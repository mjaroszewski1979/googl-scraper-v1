{% extends 'base.html' %}
{% load static %}
{% block title %}
Scraper - Home
{% endblock %}
{% block content %}
<div class="main-section">
  <i class="fas fa-info-circle fa-2x"></i>
  <h2>This is a Python application powered by requests-HTML library to provide an efficient way to parsing HTML documents using CSS Selectors. 
    Its main function is to query Google.com using the following set of queries: web address {keyword}. 
    The main risk associated with using such a program is getting blocked while scraping by sending repetitive requests from the same IP. 
    To avoid this, future improvements can be made, for example by using rotating proxies. User guide:</h2>
    <br>
    <ul>
      <li>Enter a valid web address.</li>
      <li>Type associated keyword.</li>
      <li>Select number of pages returned by google search.</li>
      <li>Tick the box if you like to save results to csv file.</li>
    </ul>
</div>
<div class="main-form">
  <table>
    <form action="{% url 'home' %}" method="post">
        {% csrf_token %}  
        {{ form.as_table }}
        <button type="submit" class="btn-form", name="save">SEND</button>
    </form>
  </table>
 
</div>
{% endblock %}


